{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Customer Lifetime Value.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbderrhmanAbdellatif/CRM/blob/master/Customer%20Lifetime%20Value.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJofSzuBdhe",
        "colab_type": "text"
      },
      "source": [
        "### Calculating Lifetime Value is the easy part. First we need to select a time window. It can be anything like 3, 6, 12, 24 months. By the equation below, we can have Lifetime Value for each customer in that specific time window:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnks6Q3KBdhk",
        "colab_type": "text"
      },
      "source": [
        "### Lifetime Value: Total Gross Revenue - Total Cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWtDurXCBdhp",
        "colab_type": "text"
      },
      "source": [
        "### This equation now gives us the historical lifetime value. If we see some customers having very high negative lifetime value historically, it could be too late to take an action. At this point, we need to predict the future with machine learning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VT3T9NbBdhu",
        "colab_type": "raw"
      },
      "source": [
        "Letâ€™s identify our path to glory:\n",
        "1-Define an appropriate time frame for Customer Lifetime Value calculation  \n",
        "2-Identify the features we are going to use to predict future and create them\n",
        "3-Calculate lifetime value (LTV) for training the machine learning model\n",
        "4-Build and run the machine learning model\n",
        "5-Check if the model is useful"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqedZRbeBdhx",
        "colab_type": "raw"
      },
      "source": [
        "RFM scores for each customer ID  are the perfect candidates for feature set. To implement it correctly, we need to split our dataset. We will take 3 months of data, calculate RFM and use it for predicting next 6 months. So we need to create two dataframes first and append RFM scores to them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "600VBmbkBdh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "from datetime import datetime, timedelta,date\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "#import machine learning related libraries\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.multioutput import MultiOutputClassifier \n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb \n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "\n",
        "import plotly.offline as pyoff\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "#initate plotly\n",
        "pyoff.init_notebook_mode()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN43obiRBdiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read data from csv and redo the data work we done before\n",
        "tx_data = pd.read_csv('https://raw.githubusercontent.com/AbderrhmanAbdellatif/CRM/master/OnlineRetail.csv',encoding= 'unicode_escape')\n",
        "tx_data['InvoiceDate'] = pd.to_datetime(tx_data['InvoiceDate'])\n",
        "tx_uk = tx_data.query(\"Country=='United Kingdom'\").reset_index(drop=True)\n",
        "tx_uk.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEmAelNBdiU",
        "colab_type": "text"
      },
      "source": [
        "# Create 3m and 6m dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UFB9N9wBdiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tx_3m = tx_uk[(tx_uk.InvoiceDate < datetime(2011,6,1)) & (tx_uk.InvoiceDate >= datetime(2011,3,1))].reset_index(drop=True)\n",
        "tx_3m.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_H-gHP8Bdii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_6m = tx_uk[(tx_uk.InvoiceDate >= datetime(2011,6,1)) & (tx_uk.InvoiceDate < datetime(2011,12,1))].reset_index(drop=True)\n",
        "tx_6m.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXyI5vFwBdir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user = pd.DataFrame(tx_3m['CustomerID'].unique())\n",
        "tx_user.columns = ['CustomerID']\n",
        "tx_user.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW-LP_rzBdi1",
        "colab_type": "text"
      },
      "source": [
        "# Order cluster method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic8CWtXKBdi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def order_cluster(cluster_field_name, target_field_name,df,ascending):\n",
        "    new_cluster_field_name = 'new_' + cluster_field_name\n",
        "    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n",
        "    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n",
        "    df_new['index'] = df_new.index\n",
        "    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n",
        "    df_final = df_final.drop([cluster_field_name],axis=1)\n",
        "    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n",
        "    return df_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ_FjkLzBdjB",
        "colab_type": "text"
      },
      "source": [
        "# calculate recency score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBVvH56nBdjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_max_purchase = tx_3m.groupby('CustomerID').InvoiceDate.max().reset_index()\n",
        "tx_max_purchase.columns = ['CustomerID','MaxPurchaseDate']\n",
        "tx_max_purchase['Recency'] = (tx_max_purchase['MaxPurchaseDate'].max() - tx_max_purchase['MaxPurchaseDate']).dt.days\n",
        "tx_user = pd.merge(tx_user, tx_max_purchase[['CustomerID','Recency']], on='CustomerID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2SSemi3BdjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3nkvg6-BdjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters=4)\n",
        "kmeans.fit(tx_user[['Recency']])\n",
        "tx_user['RecencyCluster'] = kmeans.predict(tx_user[['Recency']])\n",
        "\n",
        "tx_user = order_cluster('RecencyCluster', 'Recency',tx_user,False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg9SDCtMBdja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjUK_EcpBdjn",
        "colab_type": "text"
      },
      "source": [
        "# calcuate frequency score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-1fhcWhBdjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_frequency = tx_3m.groupby('CustomerID').InvoiceDate.count().reset_index()\n",
        "tx_frequency.columns = ['CustomerID','Frequency']\n",
        "tx_user = pd.merge(tx_user, tx_frequency, on='CustomerID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRhRhqQBdjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXqAo5k9Bdj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters=4)\n",
        "kmeans.fit(tx_user[['Frequency']])\n",
        "tx_user['FrequencyCluster'] = kmeans.predict(tx_user[['Frequency']])\n",
        "tx_user = order_cluster('FrequencyCluster', 'Frequency',tx_user,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVkczuYVBdj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3QFRNZQBdkG",
        "colab_type": "text"
      },
      "source": [
        "## calcuate revenue score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyJSLpwtBdkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_3m['Revenue'] = tx_3m['UnitPrice'] * tx_3m['Quantity']\n",
        "tx_revenue = tx_3m.groupby('CustomerID').Revenue.sum().reset_index()\n",
        "tx_user = pd.merge(tx_user, tx_revenue, on='CustomerID')\n",
        "\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "kmeans.fit(tx_user[['Revenue']])\n",
        "tx_user['RevenueCluster'] = kmeans.predict(tx_user[['Revenue']])\n",
        "tx_user = order_cluster('RevenueCluster', 'Revenue',tx_user,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2Bb9akPBdkL",
        "colab_type": "text"
      },
      "source": [
        "## overall scoring\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GjW4B_bBdkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user['OverallScore'] = tx_user['RecencyCluster'] + tx_user['FrequencyCluster'] + tx_user['RevenueCluster']\n",
        "tx_user['Segment'] = 'Low-Value'\n",
        "tx_user.loc[tx_user['OverallScore']>2,'Segment'] = 'Mid-Value' \n",
        "tx_user.loc[tx_user['OverallScore']>4,'Segment'] = 'High-Value' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKqDOHlbBdkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2kjUMKGBdkZ",
        "colab_type": "text"
      },
      "source": [
        "## calculate revenue and create a new dataframe for it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHQf6YG5Bdkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_6m['Revenue'] = tx_6m['UnitPrice'] * tx_6m['Quantity']\n",
        "tx_user_6m = tx_6m.groupby('CustomerID')['Revenue'].sum().reset_index()\n",
        "tx_user_6m.columns = ['CustomerID','m6_Revenue']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvTHiK9IBdki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_user_6m.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwZIpuolBdkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot LTV histogram\n",
        "plot_data = [\n",
        "    go.Histogram(\n",
        "        x=tx_user_6m.query('m6_Revenue < 10000')['m6_Revenue']\n",
        "    )\n",
        "]\n",
        "\n",
        "plot_layout = go.Layout(\n",
        "        title='6m Revenue'\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "pyoff.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBJMkWTvBdks",
        "colab_type": "text"
      },
      "source": [
        "### Histogram clearly shows we have customers with negative LTV. We have some outliers too. Filtering out the outliers makes sense to have a proper machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGBIYRN9Bdku",
        "colab_type": "text"
      },
      "source": [
        "# We will merge our 3 months and 6 months dataframes to see correlations between LTV and the feature set we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TA2hOQ0Bdkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_merge = pd.merge(tx_user, tx_user_6m, on='CustomerID', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaPCe49BBdk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_merge.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j5z1iuxBdk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_graph = tx_merge.query(\"m6_Revenue < 30000\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t6bh8vSBdk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_graph.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smbv_R_eBdlH",
        "colab_type": "text"
      },
      "source": [
        "# The code below merges our feature set and LTV data and plots LTV vs overall RFM score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDHl9NONBdlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_data = [\n",
        "    go.Scatter(\n",
        "        x=tx_graph.query(\"Segment == 'Low-Value'\")['OverallScore'],\n",
        "        y=tx_graph.query(\"Segment == 'Low-Value'\")['m6_Revenue'],\n",
        "        mode='markers',\n",
        "        name='Low',\n",
        "        marker= dict(size= 7,\n",
        "            line= dict(width=1),\n",
        "            color= 'blue',\n",
        "            opacity= 0.8\n",
        "           )\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        x=tx_graph.query(\"Segment == 'Mid-Value'\")['OverallScore'],\n",
        "        y=tx_graph.query(\"Segment == 'Mid-Value'\")['m6_Revenue'],\n",
        "        mode='markers',\n",
        "        name='Mid',\n",
        "        marker= dict(size= 9,\n",
        "            line= dict(width=1),\n",
        "            color= 'green',\n",
        "            opacity= 0.5\n",
        "           )\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        x=tx_graph.query(\"Segment == 'High-Value'\")['OverallScore'],\n",
        "        y=tx_graph.query(\"Segment == 'High-Value'\")['m6_Revenue'],\n",
        "        mode='markers',\n",
        "        name='High',\n",
        "        marker= dict(size= 11,\n",
        "            line= dict(width=1),\n",
        "            color= 'red',\n",
        "            opacity= 0.9\n",
        "           )\n",
        "    ),\n",
        "]\n",
        "\n",
        "plot_layout = go.Layout(\n",
        "        yaxis= {'title': \"6m LTV\"},\n",
        "        xaxis= {'title': \"RFM Score\"},\n",
        "        title='LTV'\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "pyoff.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MctmgAgBdlO",
        "colab_type": "raw"
      },
      "source": [
        "Before building the machine learning model, we need to identify what is the type of this machine learning problem. LTV itself is a regression problem. A machine learning model can predict the $ value of the LTV. But here, we want LTV segments. Because it makes it more actionable and easy to communicate with other people. By applying K-means clustering, we can identify our existing LTV groups and build segments on top of it.\n",
        "Considering business part of this analysis, we need to treat customers differently based on their predicted LTV. For this example, we will apply clustering and have 3 segments (number of segments really depends on your business dynamics and goals):\n",
        "Low LTV\n",
        "Mid LTV\n",
        "High LTV\n",
        "We are going to apply K-means clustering to decide segments and observe their characteristics:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MXIMxxZBdlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove outliers\n",
        "tx_merge = tx_merge[tx_merge['m6_Revenue']<tx_merge['m6_Revenue'].quantile(0.99)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y02CPKnBdlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_merge.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGRFIQlNBdlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating 3 clusters\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(tx_merge[['m6_Revenue']])\n",
        "tx_merge['LTVCluster'] = kmeans.predict(tx_merge[['m6_Revenue']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "140-TbJeBdld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_merge.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7bp9-oPBdlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#order cluster number based on LTV\n",
        "tx_merge = order_cluster('LTVCluster', 'm6_Revenue',tx_merge,True)\n",
        "tx_merge.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5bdGy91Bdlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creatinga new cluster dataframe\n",
        "tx_cluster = tx_merge.copy()\n",
        "\n",
        "#see details of the clusters\n",
        "tx_cluster.groupby('LTVCluster')['m6_Revenue'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNSn9rnmBdlw",
        "colab_type": "raw"
      },
      "source": [
        "2 is the best with average 8.2k LTV whereas 0 is the worst with 396.\n",
        "\n",
        "There are few more step before training the machine learning model:\n",
        "- Need to do some feature engineering. We should convert categorical columns to numerical columns.\n",
        "- We will check the correlation of features against our label, LTV clusters.\n",
        "- We will split our feature set and label (LTV) as X and y. We use X to predict y.\n",
        "- Will create Training and Test dataset. Training set will be used for building the machine learning model. We will apply our     model to Test set to see its real performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1-cXSDGz7jW",
        "colab_type": "text"
      },
      "source": [
        "### We have finished LTV clustering and here are the characteristics of each clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtqwZb1Q0dQR",
        "colab_type": "text"
      },
      "source": [
        "2 is the best with average 8.2k LTV whereas 0 is the worst with 396.\n",
        "\n",
        "There are few more step before training the machine learning model:\n",
        "\n",
        "    Need to do some feature engineering. We should convert categorical columns to numerical columns.\n",
        "    We will check the correlation of features against our label, LTV clusters.\n",
        "    We will split our feature set and label (LTV) as X and y. We use X to predict y.\n",
        "    Will create Training and Test dataset. Training set will be used for building the machine learning model. We will apply our model to Test set to see its real performance.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O254nBNx0DoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert categorical columns to numerical\n",
        "tx_class = pd.get_dummies(tx_cluster)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vfKtUd09_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_class.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etPkVeIX5SxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_moQ8tHz8iGW",
        "colab_type": "text"
      },
      "source": [
        "###calculate and show correlations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFOqwar48lha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = tx_class.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVsTiWjJ8uYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWYON2p87IB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix['LTVCluster'].sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRoTNqXF8_8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k402-_7G_ggb",
        "colab_type": "text"
      },
      "source": [
        "###create X and y, X will be feature set and y is the label - LTV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLneBPxp9GDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tx_class.drop(['LTVCluster','m6_Revenue'],axis=1)\n",
        "y = tx_class['LTVCluster']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-b1nRxf_r4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiQOhyQz_3zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5xGoReWD9vx",
        "colab_type": "text"
      },
      "source": [
        "###split training and test sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxYRyHycDz5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=56)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e438cIPyEB4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tx7GLtwEPDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgr_Kn0jEY1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " y_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NJYCUHOBEdJB",
        "colab": {}
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9fcAnRIFmrR",
        "colab_type": "text"
      },
      "source": [
        "Letâ€™s start with the first line. get_dummies() method converts categorical columns to 0â€“1 notations. See what it exactly does with the example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVqc8Nf2EnrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_cluster.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seE3LOCHHnDh",
        "colab_type": "text"
      },
      "source": [
        "This was our dataset before get_dummies(). We have one categorical column which is Segment. What happens after applying get_dummies():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uj6ivykHr2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_class.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeAunofOXSPq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHKD4RmoXUc6",
        "colab_type": "text"
      },
      "source": [
        "Segment column is gone but we have new numerical ones which represent it. We have converted it to 3 different columns with 0 and 1 and made it usable for our machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyCIhx_urwSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPtsXV9LYFLf",
        "colab_type": "text"
      },
      "source": [
        "#Gaussian Naive Bayes classifier\n",
        "\n",
        "**Gaussian NB is based on the Naive Bayes theorem with the assumption of conditional independence between every pair of features given the label of the target class. The Graph for the likelihood of the feature vectors is Gaussian.**\n",
        "\n",
        "![Gaussian Naive Bayes classifier](https://www.codespeedy.com/wp-content/uploads/2019/12/iris_gaussian.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtJNZppXseFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train,y_train)\n",
        "y_pred_test = gnb.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "NB = accuracy_score(y_test,y_pred_test)\n",
        "NB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re0QjR2wx3m0",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression \n",
        "\n",
        "**Logistic Regression is one of the basic and powerful classifiers used in the machine learning model used for binary as well as multiclass classification problems. Let us apply logistic regression in the same way as we have applied the GaussianNB on the Iris dataset that we have and will be printing the accuracy score for this model as well.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzfIvoG2x3Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(solver = 'lbfgs',multi_class='auto')\n",
        "logreg.fit(X_train,y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "LR = accuracy_score(y_test,y_pred)\n",
        "LR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfzyrWZ5svr",
        "colab_type": "text"
      },
      "source": [
        "#Decision tree classifier \n",
        "**Decision Tree classifier is a widely used classification technique where several conditions are put on the dataset in a hierarchical manner until the data corresponding to the labels is purely separated. **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1-AY-pc20r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train,y_train)\n",
        "y_pred2 = dt.predict(X_test)\n",
        "DT = accuracy_score(y_test,y_pred2)\n",
        "DT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnOo1_ga9SQM",
        "colab_type": "text"
      },
      "source": [
        "#KNN (k-nearest neighbors) classifier \n",
        "\n",
        " KNN classifier is a very simple technique for classification and it is based upon the Euclidean distance between two data points calculated by taking the distance between the feature vector.\n",
        "In case of the same distance between a data point and data points belonging to two or more different classes then, the next lowest distance is calculated and it is assumed that the data point will belong to that class. The formula to calculate Euclidean distance between two data points is:\n",
        "\n",
        "![](https://www.codespeedy.com/wp-content/uploads/2019/12/iris_euclidean.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBoe28LV-uEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf = KNeighborsClassifier(n_neighbors=3,algorithm='ball_tree')\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred3 = clf.predict(X_test)\n",
        "KNN =   accuracy_score(y_test,y_pred3)\n",
        "KNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLgG0gNE-_yf",
        "colab_type": "text"
      },
      "source": [
        "#Support Vector Machine\n",
        "Support Vector Machine or SVM is a classifier that classifies the data points into the classes(Supervised Learning) and separates those classes using a hyperplane.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aHWeZ2Q_RAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc1 = SVC(C=50,kernel='rbf',gamma=1)     \n",
        "svc1.fit(X_train,y_train)\n",
        "y_pred4 = svc1.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "SVM=accuracy_score(y_test,y_pred4)\n",
        "SVM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCOyLf2m_-aI",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Classifier \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWyIyS7D_yAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred5 = classifier.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "RF=accuracy_score(y_test,y_pred5)\n",
        "RF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRpzyPobBzpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('DTree', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=2)\n",
        "\tcv_results = model_selection.cross_val_score(model,X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1rQ8oM7Lq7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "models.append((\"LR\",LogisticRegression()))\n",
        "models.append((\"NB\",GaussianNB()))\n",
        "models.append((\"RF\",RandomForestClassifier()))\n",
        "models.append((\"SVC\",SVC()))\n",
        "models.append((\"Dtree\",DecisionTreeClassifier()))\n",
        "models.append((\"XGB\",xgb.XGBClassifier()))\n",
        "models.append((\"KNN\",KNeighborsClassifier()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THYxDg5bMTgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSoXYsOXrODu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name,model in models:\n",
        "    kfold = KFold(n_splits=2)\n",
        "    cv_result = cross_val_score(model,X_train,y_train, cv = kfold,scoring = \"accuracy\")\n",
        "    print(name, cv_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNCIdH0oRzt7",
        "colab_type": "text"
      },
      "source": [
        "#SVM Multiclassification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCi7_erV5R7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn import svm, neighbors\n",
        "\n",
        "clf = VotingClassifier([('lsvc', svm.LinearSVC()),\n",
        "                            ('knn', neighbors.KNeighborsClassifier()),\n",
        "                            ('rfor', RandomForestClassifier())])\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "confidence = clf.score(X_test, y_test)\n",
        "print('accuracy:', confidence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyLga0GzRy1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(X_train))\n",
        "StandardScaler()\n",
        "#print(scaler.mean_)\n",
        "print(scaler.transform(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qte6w9kUvuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LinearSVC(random_state=0, tol=1e-5,max_iter=1200000,dual=False)\n",
        "svm_mul_class_model = clf.fit(X_train, y_train)\n",
        "svm_mul_class_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0ysS_mtV4ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
        "       .format(svm_mul_class_model.score(X_train, y_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQsHQzqHWD6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
        "       .format(svm_mul_class_model.score(X_test[X_train.columns], y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU3sWSJAo3WQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Transforming non numerical labels into numerical labels\n",
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "# Dimension of Train and Test set \n",
        "\n",
        "# encoding train labels \n",
        "encoder.fit(y_train)\n",
        "y_train = encoder.transform(y_train)\n",
        "\n",
        "# encoding test labels \n",
        "encoder.fit(y_test)\n",
        "y_test = encoder.transform(y_test)\n",
        "names_of_predictors = list(X_train.columns.values)\n",
        "\n",
        "# Scaling the Train and Test feature set \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T9gRiQt2Pit",
        "colab_type": "text"
      },
      "source": [
        "#Hyperparameter tuning using grid search and cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ha18Dj2RL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
        "# Create the parameter grid based on the results of random search \n",
        "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]                    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFHc0A8T3PB7",
        "colab_type": "text"
      },
      "source": [
        "#Training SVM model using radial kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCYjvbfp3Juy",
        "colab_type": "code",
        "outputId": "26bb1962-2d4a-441e-8775-d73c504d7952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Performing CV to tune parameters for best SVM fit \n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
        "svm_model.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
              "                          'kernel': ['rbf']},\n",
              "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C3BlUJn_GeJ",
        "colab_type": "code",
        "outputId": "1264782b-0c8d-4b6f-e5f9-380f6e1942e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(svm_model)"
      ],
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=5, error_score=nan,\n",
            "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
            "                           class_weight=None, coef0=0.0,\n",
            "                           decision_function_shape='ovr', degree=3,\n",
            "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                           probability=False, random_state=None, shrinking=True,\n",
            "                           tol=0.001, verbose=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
            "                          'kernel': ['rbf']},\n",
            "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3-2_bIo_6VX",
        "colab_type": "text"
      },
      "source": [
        "#Confusion Matrix and Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZn4If9V__sh",
        "colab_type": "code",
        "outputId": "f7fde635-d931-4115-adf7-d4f046d9a20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# View the accuracy score\n",
        "print('Best score for training data:', svm_model.best_score_,\"\\n\") "
      ],
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score for training data: 0.8769237518645259 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdkXx4m1_pLP",
        "colab_type": "code",
        "outputId": "fa6327d9-1d2a-4f66-ac99-7b0818b99770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# View the best parameters for the model found using grid search\n",
        "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
        "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
        "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")"
      ],
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best C: 10 \n",
            "\n",
            "Best Kernel: rbf \n",
            "\n",
            "Best Gamma: 0.001 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnSwIfiOBKwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model = svm_model.best_estimator_\n",
        "Y_pred = final_model.predict(X_test_scaled)\n",
        "Y_pred_label = list(encoder.inverse_transform(Y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhFSfeUfBoz2",
        "colab_type": "code",
        "outputId": "a56a3894-9340-49fe-8d00-36d1984586b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\n",
        "print(confusion_matrix(y_test,Y_pred_label))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test,Y_pred_label))\n",
        "\n",
        "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , y_train))\n",
        "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , y_test ))\n",
        "\n",
        "svm_model.score"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[54  0  0]\n",
            " [10  2  1]\n",
            " [ 0  2  0]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.92        54\n",
            "           1       0.50      0.15      0.24        13\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.81        69\n",
            "   macro avg       0.45      0.38      0.38        69\n",
            "weighted avg       0.75      0.81      0.76        69\n",
            "\n",
            "Training set score for SVM: 0.876147\n",
            "Testing  set score for SVM: 0.811594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseSearchCV.score of GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
              "                          'kernel': ['rbf']},\n",
              "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4Xyo3aYHUl",
        "colab_type": "text"
      },
      "source": [
        "#XGBoost Multiclassification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ut2jy4OYLuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltv_xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1,objective= 'multi:softprob',n_jobs=-1).fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yekR7MCcQ8Q",
        "colab_type": "code",
        "outputId": "e4120d8c-92fa-42f5-97ee-5151da695a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "ltv_xgb_model"
      ],
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBKQ7rgncZuy",
        "colab_type": "code",
        "outputId": "1ea9213f-9665-4f10-c18a-12b075c53bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Accuracy of XGB classifier on training set: {:.2f}'\n",
        "       .format(ltv_xgb_model.score(X_train, y_train)))"
      ],
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of XGB classifier on training set: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_PdXMpudlE7",
        "colab_type": "code",
        "outputId": "ab2a03b1-03a7-4114-8f1f-c87f1d8009bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
        "       .format(ltv_xgb_model.score(X_test[X_train.columns], y_test)))"
      ],
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of XGB classifier on test set: 0.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdJjvSU5e_uv",
        "colab_type": "text"
      },
      "source": [
        "##We can identify that by looking at classification report:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXXndMKMdsgb",
        "colab_type": "code",
        "outputId": "6bcb6e52-961f-4836-8a1b-7b3313f12609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_pred = ltv_xgb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89        54\n",
            "           1       0.29      0.15      0.20        13\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.77        69\n",
            "   macro avg       0.37      0.37      0.36        69\n",
            "weighted avg       0.71      0.77      0.73        69\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btamfgPPeKa-",
        "colab_type": "text"
      },
      "source": [
        "First we need to check our benchmark. Biggest cluster we have is cluster 0 which is 76.5% of the total base. If we blindly say, every customer belongs to cluster 0, then our accuracy would be 76.5%.\n",
        "\n",
        "84% vs 76.5% tell us that our machine learning model is a useful one but needs some improvement for sure. We should find out where the model is failing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ3MG8FRkCOV",
        "colab_type": "text"
      },
      "source": [
        "Precision and recall are acceptable for 0. As an example, for cluster 0 (Low LTV), if model tells us this customer belongs to cluster 0, 90 out of 100 will be correct (precision). And the model successfully identifies 93% of actual cluster 0 customers (recall). We really need to improve the model for other clusters. For example, we barely detect 56% of Mid LTV customers. Possible actions to improve those points:\n",
        "\n",
        "    Adding more features and improve feature engineering\n",
        "    Try different models other than XGBoost\n",
        "    Apply hyper parameter tuning to current model\n",
        "    Add more data to the model if possible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp6iiUGMqSTm",
        "colab_type": "text"
      },
      "source": [
        "#Performance Comparison\n",
        "In the previous sections we have used the **accuracy_score()** method to measure the accuracy of the different algorithms. Now, we will use the `ClassificationReport` class provided by the **Yellowbrick** library to give us a visual report of how our models perform.\n",
        "\n",
        "#GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ieqiUN7qRsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b0ce0e0d-3256-4f12-e549-233d4e6495ef"
      },
      "source": [
        "from yellowbrick.classifier import ClassificationReport\n",
        "# Instantiate the classification model and visualizer\n",
        "visualizer = ClassificationReport(gnb, classes=['Won','Loss'])\n",
        "visualizer.fit(X_train,y_train) # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test) # Evaluate the model on the test data\n",
        "g = visualizer.poof() # Draw/show/poof the data"
      ],
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEYCAYAAABLOxEiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzQpLzTbP543",
        "colab_type": "text"
      },
      "source": [
        "In the code above, first we import the ClassificationReport class provided by the yellowbrick.classifier module. Next, an object visualizer of the type ClassificationReport is created. Here the first argument is the GaussianNB object gnb that was created while implementing the Naive-Bayes algorithm in the â€˜Naive-Bayesâ€™ section. The second argument contains the labels â€˜Wonâ€™ and â€˜Lossâ€™ from the â€˜Opportunity Resultâ€™ column from the sales_data dataframe.\n",
        "\n",
        "Next, we use the fit() method to train the visualizer object. This is followed by the score() method, which uses gnb object to carry out predictions as per the GaussianNB algorithm and then calculate the accuracy score of the predictions made by this algorithm. Finally, we use the poof() method to draw a plot of the different scores for the GaussianNB algorithm. Notice how the different scores are laid out against each of the labels â€˜Wonâ€™ and â€˜Lossâ€™; this enables us to visualize the scores across the different target classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-MP9_oMRH2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from yellowbrick.classifier import ClassificationReport\n",
        "# Instantiate the classification model and visualizer\n",
        "visualizer = ClassificationReport(svm_model, classes=['Won','Loss'])\n",
        "visualizer.fit(X_train,y_train) # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test) # Evaluate the model on the test data\n",
        "g = visualizer.poof() # Draw/show/poof the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ3WEwgEmoXT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}